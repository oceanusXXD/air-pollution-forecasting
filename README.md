# air-pollution-forecasting# air-pollution-forecasting



Air pollution forecasting project for predicting air quality using machine learning models.Air pollution forecasting project for predicting air quality using machine learning models.



## ğŸš€ Quick Start## Project Structure



### Using Docker (Recommended)```

air-pollution-forecasting/

```bashâ”œâ”€â”€ data/                      # Raw and processed data files

# Build and run all modelsâ”œâ”€â”€ data-processing/           # Scripts for data cleaning and preprocessing

docker-compose buildâ”œâ”€â”€ regression-analysis/       # Regression analysis notebooks and scripts

docker-compose run --rm air-pollution-classifier bashâ”œâ”€â”€ classification-analysis/   # Classification analysis notebooks and scripts

â”œâ”€â”€ regression-models/         # Regression model implementations

# Or use the quick start scriptâ””â”€â”€ classification-models/     # Classification model implementations

# Linux/Mac:```

./train_all_docker.sh

## Directory Descriptions

# Windows:

train_all_docker.bat- **data/**: Store raw and processed datasets for air pollution forecasting

```- **data-processing/**: Data cleaning, transformation, and feature engineering scripts

- **regression-analysis/**: Analysis and experiments for regression-based forecasting

See [DOCKER_GUIDE.md](DOCKER_GUIDE.md) for detailed Docker usage.- **classification-analysis/**: Analysis and experiments for classification-based forecasting

- **regression-models/**: Implementation of regression models (e.g., Linear Regression, Random Forest)

### Local Installation- **classification-models/**: Implementation of classification models (e.g., Logistic Regression, SVM)


```bash
# Install dependencies
pip install -r requirements.txt

# Run models
cd classification-models
python xgboost_classifier.py
python ft_transformer_classifier.py
python deepgbm_classifier.py
```

## Project Structure

```
air-pollution-forecasting/
â”œâ”€â”€ data_artifacts/            # Processed data in parquet format
â”œâ”€â”€ classification-models/     # Classification model implementations
â”œâ”€â”€ classification-analysis/   # Training results and visualizations
â”œâ”€â”€ Dockerfile                 # Docker container definition
â”œâ”€â”€ docker-compose.yml         # Docker Compose configuration
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ CPU_TRAINING_GUIDE.md     # CPU optimization guide
```

## ğŸ“Š Available Models

### Classification Models (CO Level Prediction)

1. **XGBoost Classifier** - Baseline gradient boosting model
2. **FT-Transformer** - Feature Tokenizer Transformer for tabular data
3. **DeepGBM** - Hybrid model combining XGBoost + Deep Neural Networks

All models predict CO pollution levels across multiple horizons:
- h1: 1 hour ahead
- h6: 6 hours ahead
- h12: 12 hours ahead
- h24: 24 hours ahead

## Directory Descriptions

- **data_artifacts/**: Processed datasets in parquet format with train/valid/test splits
- **classification-models/**: Implementation of classification models
- **classification-analysis/**: Training outputs including metrics, plots, and saved models
- **regression-models/**: Implementation of regression models (future work)
- **regression-analysis/**: Analysis for regression-based forecasting (future work)

## ğŸ“– Documentation

- [DOCKER_GUIDE.md](DOCKER_GUIDE.md) - Comprehensive Docker usage guide
- [CPU_TRAINING_GUIDE.md](CPU_TRAINING_GUIDE.md) - CPU training optimization tips
- [USAGE_modeling.md](USAGE_modeling.md) - Modeling methodology and best practices

## ğŸ”§ System Requirements

### Local Installation
- Python 3.11+
- 8GB+ RAM
- CPU: 4+ cores recommended

### Docker Installation
- Docker 20.10+
- Docker Compose 2.0+
- 8GB+ RAM
- 5GB+ free disk space

## ğŸ’¡ Features

- âœ… Three state-of-the-art classification models
- âœ… CPU-optimized hyperparameters (batch_size=32)
- âœ… Progress bars and detailed training logs
- âœ… Automatic early stopping
- âœ… Comprehensive evaluation metrics and visualizations
- âœ… Docker support for reproducible training
- âœ… Multi-horizon forecasting (1, 6, 12, 24 hours)

## ğŸ“ˆ Model Performance

All models are evaluated on:
- Accuracy
- F1-score (macro & weighted)
- Per-class precision/recall
- Confusion matrices
- Comparison with naive baseline

Results are saved in `classification-analysis/{model_name}/h{horizon}/`

## ğŸ› Troubleshooting

### Out of Memory
- Reduce batch_size in model code
- Use Docker with memory limits
- Close other applications

### Slow Training
- Models are optimized for CPU training
- Expected training time: 2-4 hours per model
- Use Docker to run in background

### Missing Data
Ensure `data_artifacts/splits/` contains:
```
data_artifacts/splits/
â”œâ”€â”€ h1/
â”‚   â”œâ”€â”€ train.parquet
â”‚   â”œâ”€â”€ valid.parquet
â”‚   â””â”€â”€ test.parquet
â”œâ”€â”€ h6/
â”œâ”€â”€ h12/
â””â”€â”€ h24/
```

## ğŸ“ License

Only for unsw 9417 team project use
